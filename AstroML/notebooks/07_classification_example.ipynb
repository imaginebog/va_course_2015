{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to modify the ``DATA_HOME`` variable to the location of the datasets. \n",
    "\n",
    "In this tutorial we'll use the colors of over 700,000 stars and quasars from the \n",
    "Sloan Digital Sky Survey. 500,000 of them are training data, spectroscopically \n",
    "identified as stars or quasars. The remaining 200,000\n",
    "have been classified based on their photometric colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_HOME = os.path.abspath('C:/temp/AstroML/data/sdss_colors/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use a Naive Bayes estimator to classify the objects.\n",
    "First, we will construct our training data and test data arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load(os.path.join(DATA_HOME, 'sdssdr6_colors_class_train.npy'))\n",
    "test_data = np.load(os.path.join(DATA_HOME, 'sdssdr6_colors_class.200000.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as a *record array*, which is a convenient format for\n",
    "collections of labeled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_data.dtype.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_data['u-g'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must put these into arrays of shape ``(n_samples, n_features)``\n",
    "in order to pass them to routines in scikit-learn. Training samples\n",
    "with zero-redshift are stars, while samples with positive redshift are quasars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.vstack([train_data['u-g'],\n",
    "                     train_data['g-r'],\n",
    "                     train_data['r-i'],\n",
    "                     train_data['i-z']]).T\n",
    "y_train = (train_data['redshift'] > 0).astype(int)\n",
    "\n",
    "X_test = np.vstack([test_data['u-g'],\n",
    "                    test_data['g-r'],\n",
    "                    test_data['r-i'],\n",
    "                    test_data['i-z']]).T\n",
    "y_test = (test_data['label'] == 0).astype(int)\n",
    "\n",
    "print(\"training data: \") \n",
    "print(X_train.shape)\n",
    "print(\"test data: \") \n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we’ve set this up so that quasars have ``y = 1``,\n",
    "and stars have ``y = 0``. Now we’ll set up a Naive Bayes classifier.\n",
    "This will fit a four-dimensional uncorrelated gaussian to each\n",
    "distribution, and from these gaussians quickly predict the label\n",
    "for a test point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check our accuracy. This is the fraction of labels that are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = float(np.sum(y_test == y_pred)) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 61% accuracy. Not very good. But we must be careful here:\n",
    "the accuracy does not always tell the whole story. In our data,\n",
    "there are many more stars than quasars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.sum(y_test == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.sum(y_test == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stars outnumber Quasars by a factor of 14 to 1. In cases like this,\n",
    "it is much more useful to evaluate the fit based on *precision* and\n",
    "*recall*. Because there are many fewer quasars than stars, we’ll call\n",
    "a quasar a positive label and a star a negative label. The precision\n",
    "asks what fraction of positively labeled points are correctly labeled:\n",
    "\n",
    "$\\mathrm{precision = \\frac{True\\ Positives}{True\\ Positives + False\\ Positives}}$\n",
    "\n",
    "The recall asks what fraction of positive samples are correctly identified:\n",
    "\n",
    "$\\mathrm{recall = \\frac{True\\ Positives}{True\\ Positives + False\\ Negatives}}$\n",
    "\n",
    "We can calculate this for our results as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TP = np.sum((y_pred == 1) & (y_test == 1))  # true positives\n",
    "FP = np.sum((y_pred == 1) & (y_test == 0))  # false positives\n",
    "FN = np.sum((y_pred == 0) & (y_test == 1))  # false negatives\n",
    "print(\"precision:\") \n",
    "print(TP / float(TP + FP))\n",
    "print(\"recall:   \") \n",
    "print(TP / float(TP + FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, these can be computed using the tools in the metrics sub-package of scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"precision:\") \n",
    "print(metrics.precision_score(y_test, y_pred))\n",
    "print(\"recall:   \") \n",
    "print(metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and Recall tell different stories about the performance of the classifier. Ideally one would try to create a classifier with a high precision and high recall but this is not always possible, and sometimes raising the precision will decrease the recall or viceversa (why?).\n",
    "\n",
    "Think about situations when you'll want a high precision classifier even if the recall is poor, and viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful metric is the F1 score, which gives a single score based on the precision and recall for the class:\n",
    "\n",
    "$\\mathrm{F1 = 2\\frac{precision * recall}{precision + recall}}$\n",
    "\n",
    "In a perfect classification, the precision, recall, and F1 score are all equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"F1 score:\") \n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, sklearn.metrics provides a function that computes all\n",
    "of these scores, and returns a nicely formatted string. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, y_pred, target_names=['Stars', 'QSOs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for Gaussian Naive Bayes, our QSO recall is fairly good:\n",
    "we are correctly identifying 95% of all quasars. The precision, on the\n",
    "other hand, is much worse. Of the points we label quasars, only 14% of\n",
    "them are correctly labeled. This low precision leads to an F1-score of\n",
    "only 0.25. This is not an optimal classification of our data.\n",
    "Apparently Naive Bayes is a bit too naive for this problem, so lets check \n",
    "with some other classifiers. Remember that the documentation is in http://scikit-learn.org/stable/supervised_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the classifier with a DecisionTreeClassifier and compare the results with the Naive Bayes. Which metric would you choose for doing the comparison? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try with a Random Forest, that is a ensemble of a number of Decision Trees. Replace the classifier with a RandomForestClassifier and compare the results. \n",
    "Which parameters can be adjusted in this classifier? Experiment with the most important parameters and try to create a better classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
